{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "L4",
      "machine_shape": "hm"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "!pip install transformers datasets scikit-learn --quiet\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "m6V2p5BKZWno",
        "outputId": "83576b35-6cc9-4430-c9df-8a8202a4da45"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[?25l   \u001b[90m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m \u001b[32m0.0/491.2 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K   \u001b[90m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m \u001b[32m491.2/491.2 kB\u001b[0m \u001b[31m38.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h\u001b[?25l   \u001b[90m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m \u001b[32m0.0/116.3 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K   \u001b[90m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m \u001b[32m116.3/116.3 kB\u001b[0m \u001b[31m14.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h\u001b[?25l   \u001b[90m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m \u001b[32m0.0/183.9 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K   \u001b[90m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m \u001b[32m183.9/183.9 kB\u001b[0m \u001b[31m23.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h\u001b[?25l   \u001b[90m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m \u001b[32m0.0/143.5 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K   \u001b[90m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m \u001b[32m143.5/143.5 kB\u001b[0m \u001b[31m18.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h\u001b[?25l   \u001b[90m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m \u001b[32m0.0/194.8 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K   \u001b[90m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m \u001b[32m194.8/194.8 kB\u001b[0m \u001b[31m24.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "gcsfs 2025.3.2 requires fsspec==2025.3.2, but you have fsspec 2024.12.0 which is incompatible.\n",
            "torch 2.6.0+cu124 requires nvidia-cublas-cu12==12.4.5.8; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-cublas-cu12 12.5.3.2 which is incompatible.\n",
            "torch 2.6.0+cu124 requires nvidia-cuda-cupti-cu12==12.4.127; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-cuda-cupti-cu12 12.5.82 which is incompatible.\n",
            "torch 2.6.0+cu124 requires nvidia-cuda-nvrtc-cu12==12.4.127; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-cuda-nvrtc-cu12 12.5.82 which is incompatible.\n",
            "torch 2.6.0+cu124 requires nvidia-cuda-runtime-cu12==12.4.127; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-cuda-runtime-cu12 12.5.82 which is incompatible.\n",
            "torch 2.6.0+cu124 requires nvidia-cudnn-cu12==9.1.0.70; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-cudnn-cu12 9.3.0.75 which is incompatible.\n",
            "torch 2.6.0+cu124 requires nvidia-cufft-cu12==11.2.1.3; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-cufft-cu12 11.2.3.61 which is incompatible.\n",
            "torch 2.6.0+cu124 requires nvidia-curand-cu12==10.3.5.147; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-curand-cu12 10.3.6.82 which is incompatible.\n",
            "torch 2.6.0+cu124 requires nvidia-cusolver-cu12==11.6.1.9; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-cusolver-cu12 11.6.3.83 which is incompatible.\n",
            "torch 2.6.0+cu124 requires nvidia-cusparse-cu12==12.3.1.170; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-cusparse-cu12 12.5.1.3 which is incompatible.\n",
            "torch 2.6.0+cu124 requires nvidia-nvjitlink-cu12==12.4.127; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-nvjitlink-cu12 12.5.82 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0m"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "mmXmdj5EZXKE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RINc9m60tPK0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 950,
          "referenced_widgets": [
            "cae8d8aab6ce46a98d8f94ae149b4e1f",
            "5d32a57fd8f74ae3be5388859412ea85",
            "f82f8ba9cd7a48d8a69b7e5561bb9dff",
            "10fc94fb34d045f68655bbf4da33a7a5",
            "37574ced44d44b008cb40db16d17559e",
            "a7898d5d375d487487f339a7c95614be",
            "e51bd609aa7945dab9aeaac4154d6743",
            "8b7ab7cb0d8a40fb9e38ce5774c2e61a",
            "5b090a1ca91b4ab58147a074c728fe52",
            "e4e8ccbf2ac9437e8a0bbe62ecfb30cc",
            "c3aeb21876854c1c937d6bb95eb2ecbb",
            "a86da02ca2de4812946b59e0af424045",
            "464ab6ccb5094b9dbae2c0f7cfd821c1",
            "57619b3096c1410fa26e0f3089e218b6",
            "d90e870fb9e24cf7858d3221a29eeb71",
            "186604a93d75445fa6ad6a6a79ee9e86",
            "99e645bd76e044f8aec70cbd6201c63c",
            "3415cc7bc0504940b99d992e816399a6",
            "b8a6f0069b4f4f05b6936517c147214c",
            "cccda67fb8544756a8916357f530c70e",
            "c196ce70bb92477594a920a1473d2c31",
            "36597ef483f94a69960809ea77e20b8f",
            "1a814afd54294019886d40dcea58710a",
            "b2bfbcec83fb40798bb95d1ad25b8c07",
            "428896a9a71f4814bbc1060d8f3edead",
            "aa231c253f3e4548949358f58cc7ff65",
            "97d76640baa84a3189de5395c2192679",
            "52c199c5a9754e4e899e0f43af322024",
            "bdaf8cf241364a378fe4b1e61d2bd3d2",
            "a8b0581dc61346d2945842d3cc0fcf27",
            "11500380de6a47fbaeadc76ddc4e62d7",
            "e656708e1369407aa818a4761d3deba7",
            "e08d392fa3424c08bd43b5c22889507a",
            "e68c7a702b2943e9a0d584b6bb0e0f86",
            "5739e38d7c86499ab699eeea2ae04552",
            "e8a3c8f08932469bac2e7445a8ccc8f9",
            "377c74ba02e34249b8da9bf610d9edf5",
            "064721634a8e4f78ae34ce7f73bfc91d",
            "db7f9db02e89447d9bd0d8c487b90946",
            "c87ff8d99ab24d65aef77dda0946240d",
            "5110786092fe4359b6fcc0abdb668cf1",
            "75ceeb9313bc4d9b9fd1d3e2527f9de8",
            "dddef33a002040d3b71ea932b8129579",
            "3dd59eb5ea654b6689e25c0a4adc71f8",
            "47b3baa848b145fd82aa1d8a58f0ce03",
            "736f7aa4136b4c4eb627dd2c39737fd7",
            "1ccc4d3c51ef43188360c0de51c81fd8",
            "3b83d87bcc2b40ff828817c9e5fc6a48",
            "ebcaec70197b4eac8567639f7b4f1d77",
            "1825a04dfd2d4b289ca859c324c42802",
            "2b924c65004144ec93ec7216121c6a71",
            "0cc98cc07af240c8b439544968ace5d9",
            "1eafa109e8204914b61c0bdf6ddbee45",
            "8e9eb2825fa240208cfd48a42f684e34",
            "8326290a306440ebaf53701f79c8e8b8",
            "614be408fc2844648e23872562ddcd6a",
            "3585cf8a15d54b6394e1e031251ac7d9",
            "32f69c9a2a704a5a9eee796efc6bc69d",
            "b00b3c154b3846329c081491a5de4b9d",
            "8c787d6af56142809fbd41e8ef75a26c",
            "e641c29b4ce64623ab3adfacc2618a1e",
            "f8c5beb868514d46ac53c9427e8e6f96",
            "943a6e8a2efe403d884629183baf7eeb",
            "1a3607e7ad384a709afe0e4cc4b9c8e5",
            "cca24b2efec444ca9f1cb734e347a50a",
            "0a0bc4422bd143028d19fe4071b4560c",
            "ad83ee0e8d604011a452da9f03d4660a",
            "24a678dac16e44399b9fd080399a3abe",
            "89a73d573e13454199ba47144bfcbe9d",
            "68ada364f624461e991c0c23b64ad24e",
            "59675e275ac947898dfb1e1c1875eb41",
            "068ccf6bcdba437fb318775866e21095",
            "9e2fc85dae624867af82b5c8c6606d7d",
            "c5933a24ca094d92acee8ca64b2215f1",
            "fe7fb984ee0c4b0eaffd9298994e1667",
            "63a2093c77234edeb178c13f1602b888",
            "caa39d530fd546c7a10205f616539849",
            "4a95947a38b347d4a0cfd04727484afc",
            "51fbb034267d4fbc83c4c56976ed8101",
            "526ae768052349aca583535f4d0f1a14",
            "9996c86eee3a459ab173f65ae22d09ba",
            "3c918ab1e94c4133baf4f3cc1a87c40f",
            "6965366af083458abbd37c544d9697b8",
            "1021bbb654724829a3c0e17d4c6443b9",
            "8ccf611668664ea2b681b8d3109d1f27",
            "88866e70bf204b6c939a2db0c894bf69",
            "6da91c52ab6a479c9447c2150a9b8fcb",
            "47d2afbdbbfb4af4aae374d48bac2787",
            "44719e6a5aef419eb4af43687f971d70",
            "61db584c56bc41d881fa02ac977177b4",
            "e3404a423e18464e999510c020ea5037",
            "432a1629bf524293a5d80057c4bdd1b6",
            "c60b95dc497d47d6a5afc1ce30623143",
            "d9d58f698f944c1688a2bf646a8b9f46",
            "dd4dea1671b942938bffb713876aa72f",
            "61d1cadf28384cfda3513d52c09b7855",
            "33e9a055517e43deb17e0f247c923438",
            "5a81ec2146074350be5b3a14fe4b46a0",
            "37114d490031429db2da7cc6a23f4cea"
          ]
        },
        "outputId": "d2779ec5-0a58-4615-defc-acc06399bbdf"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/huggingface_hub/utils/_auth.py:94: UserWarning: \n",
            "The secret `HF_TOKEN` does not exist in your Colab secrets.\n",
            "To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n",
            "You will be able to reuse this secret in all of your notebooks.\n",
            "Please note that authentication is recommended but still optional to access public models or datasets.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "tokenizer_config.json:   0%|          | 0.00/48.0 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "cae8d8aab6ce46a98d8f94ae149b4e1f"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "vocab.txt:   0%|          | 0.00/232k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "a86da02ca2de4812946b59e0af424045"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "tokenizer.json:   0%|          | 0.00/466k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "1a814afd54294019886d40dcea58710a"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "config.json:   0%|          | 0.00/570 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "e68c7a702b2943e9a0d584b6bb0e0f86"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\ud83d\udd35 Fold 1 Ba\u015fl\u0131yor...\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Map:   0%|          | 0/70000 [00:00<?, ? examples/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "47b3baa848b145fd82aa1d8a58f0ce03"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Map:   0%|          | 0/70000 [00:00<?, ? examples/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "614be408fc2844648e23872562ddcd6a"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Xet Storage is enabled for this repo, but the 'hf_xet' package is not installed. Falling back to regular HTTP download. For better performance, install the package with: `pip install huggingface_hub[hf_xet]` or `pip install hf_xet`\n",
            "WARNING:huggingface_hub.file_download:Xet Storage is enabled for this repo, but the 'hf_xet' package is not installed. Falling back to regular HTTP download. For better performance, install the package with: `pip install huggingface_hub[hf_xet]` or `pip install hf_xet`\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "model.safetensors:   0%|          | 0.00/440M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "ad83ee0e8d604011a452da9f03d4660a"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Fold 1 Epoch 1: 100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 4375/4375 [12:32<00:00,  5.81it/s, loss=0.444]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u2705 Fold 1 Epoch 1 - Accuracy: 0.7852 | Precision: 0.7857 | Recall: 0.7852 | F1: 0.7815\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Fold 1 Epoch 2: 100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 4375/4375 [12:31<00:00,  5.82it/s, loss=0.39]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u2705 Fold 1 Epoch 2 - Accuracy: 0.8168 | Precision: 0.8202 | Recall: 0.8168 | F1: 0.8142\n",
            "\n",
            "\ud83d\udd35 Fold 2 Ba\u015fl\u0131yor...\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Map:   0%|          | 0/70000 [00:00<?, ? examples/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "4a95947a38b347d4a0cfd04727484afc"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Map:   0%|          | 0/70000 [00:00<?, ? examples/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "44719e6a5aef419eb4af43687f971d70"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Fold 2 Epoch 1: 100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 4375/4375 [12:31<00:00,  5.82it/s, loss=0.47]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u2705 Fold 2 Epoch 1 - Accuracy: 0.7747 | Precision: 0.7810 | Recall: 0.7747 | F1: 0.7661\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Fold 2 Epoch 2: 100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 4375/4375 [12:31<00:00,  5.82it/s, loss=0.434]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u2705 Fold 2 Epoch 2 - Accuracy: 0.8165 | Precision: 0.8207 | Recall: 0.8165 | F1: 0.8160\n",
            "\n",
            "\ud83c\udfaf Stratified K-Fold Sonu\u00e7lar\u0131:\n",
            "Fold 1 - Accuracy: 0.8168 | Precision: 0.8202 | Recall: 0.8168 | F1: 0.8142 | Training Loss: 0.4617\n",
            "Fold 2 - Accuracy: 0.8165 | Precision: 0.8207 | Recall: 0.8165 | F1: 0.8160 | Training Loss: 0.4619\n",
            "\n",
            "\ud83d\udcca Ortalama Sonu\u00e7lar:\n",
            "Average Accuracy: 0.8166\n",
            "Average Precision: 0.8205\n",
            "Average Recall: 0.8166\n",
            "Average F1: 0.8151\n",
            "Average Training Loss: 0.4618\n",
            "\u2705 Model ba\u015far\u0131yla kaydedildi: /content/drive/MyDrive/data/bert_model_20250428_0728\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from datasets import Dataset\n",
        "from transformers import BertTokenizer, BertForSequenceClassification\n",
        "import torch\n",
        "from sklearn.model_selection import StratifiedKFold\n",
        "from sklearn.utils.class_weight import compute_class_weight\n",
        "from imblearn.over_sampling import RandomOverSampler\n",
        "from sklearn.metrics import accuracy_score, precision_recall_fscore_support\n",
        "from torch.utils.data import DataLoader\n",
        "from torch.optim import AdamW\n",
        "from transformers import get_cosine_schedule_with_warmup\n",
        "from tqdm import tqdm\n",
        "import torch.nn as nn\n",
        "from datetime import datetime\n",
        "\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "# 1. Veriyi y\u00fckle ve etiketleri d\u00f6n\u00fc\u015ft\u00fcr\n",
        "df = pd.read_csv(\"/content/drive/MyDrive/data/train_cleaned_augamented_cleaned.csv\")\n",
        "le = LabelEncoder()\n",
        "df[\"label_id\"] = le.fit_transform(df[\"label\"])\n",
        "\n",
        "# Oversampling uygula\n",
        "ros = RandomOverSampler()\n",
        "X_resampled, y_resampled = ros.fit_resample(df[[\"text\"]], df[\"label_id\"])\n",
        "resampled_df = pd.DataFrame({\"text\": X_resampled[\"text\"], \"label_id\": y_resampled})\n",
        "\n",
        "# Tokenizer haz\u0131rla\n",
        "tokenizer = BertTokenizer.from_pretrained(\"bert-base-uncased\")\n",
        "num_labels = df[\"label_id\"].nunique()\n",
        "\n",
        "# Tokenization fonksiyonu\n",
        "def tokenize(example):\n",
        "    encoding = tokenizer(example[\"text\"], padding=\"max_length\", truncation=True, max_length=128)\n",
        "    encoding[\"labels\"] = int(example[\"label_id\"])\n",
        "    return encoding\n",
        "\n",
        "# Stratified K-Fold ayar\u0131\n",
        "k_folds = 2\n",
        "skf = StratifiedKFold(n_splits=k_folds, shuffle=True, random_state=42)\n",
        "\n",
        "# Fold skorlar\u0131 tutmak i\u00e7in listeler\n",
        "fold_accuracies = []\n",
        "fold_losses = []\n",
        "fold_precisions = []\n",
        "fold_recalls = []\n",
        "fold_f1s = []\n",
        "\n",
        "# Stratified K-Fold E\u011fitim\n",
        "for fold_idx, (train_idx, val_idx) in enumerate(skf.split(resampled_df[\"text\"], resampled_df[\"label_id\"])):\n",
        "    print(f\"\\n\ud83d\udd35 Fold {fold_idx+1} Ba\u015fl\u0131yor...\")\n",
        "\n",
        "    # Fold'a \u00f6zel train/val ay\u0131r\n",
        "    train_df = resampled_df.iloc[train_idx]\n",
        "    val_df = resampled_df.iloc[val_idx]\n",
        "\n",
        "    # Fold'a \u00f6zel Class Weights hesapla\n",
        "    class_weights = compute_class_weight(class_weight=\"balanced\",\n",
        "                                         classes=np.unique(train_df[\"label_id\"]),\n",
        "                                         y=train_df[\"label_id\"])\n",
        "    class_weights = torch.tensor(class_weights, dtype=torch.float).to(device)\n",
        "\n",
        "    # Huggingface Dataset format\u0131\n",
        "    train_dataset = Dataset.from_pandas(train_df[[\"text\", \"label_id\"]])\n",
        "    val_dataset = Dataset.from_pandas(val_df[[\"text\", \"label_id\"]])\n",
        "\n",
        "    tokenized_train = train_dataset.map(tokenize)\n",
        "    tokenized_val = val_dataset.map(tokenize)\n",
        "\n",
        "    tokenized_train.set_format(type=\"torch\", columns=[\"input_ids\", \"attention_mask\", \"labels\"])\n",
        "    tokenized_val.set_format(type=\"torch\", columns=[\"input_ids\", \"attention_mask\", \"labels\"])\n",
        "\n",
        "    # DataLoader\n",
        "    train_dataloader = DataLoader(tokenized_train, batch_size=16, shuffle=True)\n",
        "    val_dataloader = DataLoader(tokenized_val, batch_size=16)\n",
        "\n",
        "    # Modeli yeniden ba\u015flat\n",
        "    model = BertForSequenceClassification.from_pretrained(\n",
        "        \"bert-base-uncased\",\n",
        "        num_labels=num_labels\n",
        "    ).to(device)\n",
        "\n",
        "    optimizer = AdamW(model.parameters(), lr=2e-5, weight_decay=0.01)\n",
        "    total_steps = len(train_dataloader) * 4\n",
        "    scheduler = get_cosine_schedule_with_warmup(\n",
        "        optimizer, num_warmup_steps=int(0.1 * total_steps), num_training_steps=total_steps\n",
        "    )\n",
        "\n",
        "    loss_fn = nn.CrossEntropyLoss(weight=class_weights)\n",
        "\n",
        "    # \ud83d\udccd Early Stopping Ayarlar\u0131\n",
        "    best_acc = 0\n",
        "    best_precision = 0\n",
        "    best_recall = 0\n",
        "    best_loss = float('inf')\n",
        "    best_f1 = 0\n",
        "    patience = 2\n",
        "    patience_counter = 0\n",
        "\n",
        "    # \ud83d\udcda E\u011fitim\n",
        "    for epoch in range(2):\n",
        "        model.train()\n",
        "        total_loss = 0\n",
        "        loop = tqdm(train_dataloader, desc=f\"Fold {fold_idx+1} Epoch {epoch+1}\")\n",
        "\n",
        "        for batch in loop:\n",
        "            batch = {k: v.to(device) for k, v in batch.items()}\n",
        "            labels = batch.pop(\"labels\")\n",
        "\n",
        "            outputs = model(**batch)\n",
        "            loss = loss_fn(outputs.logits, labels)\n",
        "            loss.backward()\n",
        "\n",
        "            optimizer.step()\n",
        "            scheduler.step()\n",
        "            optimizer.zero_grad()\n",
        "\n",
        "            total_loss += loss.item()\n",
        "            loop.set_postfix(loss=loss.item())\n",
        "\n",
        "        # \ud83d\udcc9 Validation\n",
        "        model.eval()\n",
        "        all_preds = []\n",
        "        all_labels = []\n",
        "\n",
        "        with torch.no_grad():\n",
        "            for batch in val_dataloader:\n",
        "                batch = {k: v.to(device) for k, v in batch.items()}\n",
        "                labels = batch.pop(\"labels\")\n",
        "                outputs = model(**batch)\n",
        "                preds = torch.argmax(outputs.logits, dim=1)\n",
        "\n",
        "                all_preds.extend(preds.cpu().numpy())\n",
        "                all_labels.extend(labels.cpu().numpy())\n",
        "\n",
        "        precision, recall, f1, _ = precision_recall_fscore_support(all_labels, all_preds, average='weighted')\n",
        "        acc = accuracy_score(all_labels, all_preds)\n",
        "\n",
        "        print(f\"\u2705 Fold {fold_idx+1} Epoch {epoch+1} - Accuracy: {acc:.4f} | Precision: {precision:.4f} | Recall: {recall:.4f} | F1: {f1:.4f}\")\n",
        "\n",
        "        # \ud83d\udd25 En iyi modeli kaydet\n",
        "        if f1 > best_f1:\n",
        "            best_f1 = f1\n",
        "            best_acc = acc\n",
        "            best_precision = precision\n",
        "            best_recall = recall\n",
        "            best_loss = total_loss / len(train_dataloader)\n",
        "            patience_counter = 0\n",
        "        else:\n",
        "            patience_counter += 1\n",
        "\n",
        "        if patience_counter >= patience:\n",
        "            print(f\"\u23f9\ufe0f Fold {fold_idx+1} i\u00e7in early stopping tetiklendi! Epoch: {epoch+1}\")\n",
        "            break\n",
        "\n",
        "    # \ud83d\udce5 Fold sonu EN \u0130Y\u0130 SONU\u00c7LARI kaydet\n",
        "    fold_accuracies.append(best_acc)\n",
        "    fold_losses.append(best_loss)\n",
        "    fold_precisions.append(best_precision)\n",
        "    fold_recalls.append(best_recall)\n",
        "    fold_f1s.append(best_f1)\n",
        "\n",
        "# \ud83c\udfaf E\u011fitim Bittikten Sonra Sonu\u00e7lar\u0131 Yazd\u0131r\n",
        "print(\"\\n\ud83c\udfaf Stratified K-Fold Sonu\u00e7lar\u0131:\")\n",
        "\n",
        "for i in range(len(fold_accuracies)):\n",
        "    print(f\"Fold {i+1} - Accuracy: {fold_accuracies[i]:.4f} | Precision: {fold_precisions[i]:.4f} | Recall: {fold_recalls[i]:.4f} | F1: {fold_f1s[i]:.4f} | Training Loss: {fold_losses[i]:.4f}\")\n",
        "\n",
        "print(\"\\n\ud83d\udcca Ortalama Sonu\u00e7lar:\")\n",
        "print(f\"Average Accuracy: {np.mean(fold_accuracies):.4f}\")\n",
        "print(f\"Average Precision: {np.mean(fold_precisions):.4f}\")\n",
        "print(f\"Average Recall: {np.mean(fold_recalls):.4f}\")\n",
        "print(f\"Average F1: {np.mean(fold_f1s):.4f}\")\n",
        "print(f\"Average Training Loss: {np.mean(fold_losses):.4f}\")\n",
        "\n",
        "# 11. Modeli Kaydet\n",
        "timestamp = datetime.now().strftime(\"%Y%m%d_%H%M\")\n",
        "save_path = f\"/content/drive/MyDrive/data/bert_model_{timestamp}\"\n",
        "model.save_pretrained(save_path)\n",
        "tokenizer.save_pretrained(save_path)\n",
        "print(f\"\u2705 Model ba\u015far\u0131yla kaydedildi: {save_path}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "HUOTGrcsZpfq"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}
